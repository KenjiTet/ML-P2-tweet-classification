{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get folder path\n",
    "folder_path = os.path.dirname(os.path.dirname(os.path.realpath(\"EDA.ipynb\")))\n",
    "\n",
    "#get small data path\n",
    "small_neg_path = os.path.join(folder_path, \"twitter-datasets\", \"train_neg.txt\")\n",
    "small_pos_path = os.path.join(folder_path, \"twitter-datasets\", \"train_pos.txt\")\n",
    "test_path = os.path.join(folder_path, \"twitter-datasets\", \"test_data.txt\")\n",
    "\n",
    "#create small data dataframe\n",
    "with open(small_neg_path, 'r') as file:\n",
    "    lines_neg = file.readlines()\n",
    "with open(small_pos_path, 'r') as file:\n",
    "    lines_pos = file.readlines()\n",
    "with open(test_path, 'r') as file:\n",
    "    lines_test = file.readlines()\n",
    "\n",
    "small_neg_df = pd.DataFrame({'Tweets': lines_neg, 'Sentiment': -1})\n",
    "small_pos_df = pd.DataFrame({'Tweets': lines_pos, 'Sentiment': 1})\n",
    "test_df= pd.DataFrame({'Tweets': lines_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag of words creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>yur</th>\n",
       "      <th>zac</th>\n",
       "      <th>zayn</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 4001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  01  02  04  05  06  07  08  10  ...  yur  zac  zayn  zealand  \\\n",
       "0        0    0   0   0   0   0   0   0   0   2  ...    0    0     0        0   \n",
       "1        0    0   0   0   0   0   0   0   0   0  ...    0    0     0        0   \n",
       "2        0    0   0   0   0   0   0   0   0   0  ...    0    0     0        0   \n",
       "3        0    0   0   0   0   0   0   0   0   0  ...    0    0     0        0   \n",
       "4        0    0   0   0   0   0   0   0   0   0  ...    0    0     0        0   \n",
       "...     ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...   ...      ...   \n",
       "199995   0    0   0   0   0   0   0   0   0   0  ...    0    0     0        0   \n",
       "199996   1    0   0   0   0   0   0   0   0   0  ...    0    0     0        0   \n",
       "199997   0    0   0   0   0   0   0   0   0   0  ...    0    0     0        0   \n",
       "199998   0    0   0   0   0   0   0   0   0   0  ...    0    0     0        0   \n",
       "199999   0    0   0   0   0   0   0   0   0   0  ...    0    0     0        0   \n",
       "\n",
       "        zinc  zip  zone  zoo  zoom  Sentiment  \n",
       "0          0    0     0    0     0         -1  \n",
       "1          0    0     0    0     0         -1  \n",
       "2          0    0     0    0     0         -1  \n",
       "3          0    0     0    0     0         -1  \n",
       "4          0    0     0    0     0         -1  \n",
       "...      ...  ...   ...  ...   ...        ...  \n",
       "199995     0    0     0    0     0          1  \n",
       "199996     0    0     0    0     0          1  \n",
       "199997     0    0     0    0     0          1  \n",
       "199998     0    0     0    0     0          1  \n",
       "199999     0    0     0    0     0          1  \n",
       "\n",
       "[200000 rows x 4001 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Assuming your original dataframe is named 'original_df' and contains a 'Tweets' column\n",
    "# You may need to adjust column names based on your actual dataframe structure\n",
    "\n",
    "# Combine positive and negative dataframes\n",
    "combined_df = pd.concat([small_neg_df, small_pos_df], ignore_index=True)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer(max_features=4000)  # You can adjust max_features as needed\n",
    "\n",
    "# Fit and transform the combined data\n",
    "bow_matrix = count_vectorizer.fit_transform(combined_df['Tweets'])\n",
    "\n",
    "# Convert the BoW matrix to a DataFrame\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the 'Sentiment' column back to the BoW DataFrame\n",
    "bow_df['Sentiment'] = combined_df['Sentiment']\n",
    "\n",
    "# Display the resulting BoW DataFrame\n",
    "bow_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sum the occurrences of each word across all tweets\n",
    "word_counts = bow_df.drop(columns=['Sentiment']).sum()\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "word_counts.sort_values(ascending=False).head(20).plot(kind='bar')\n",
    "plt.title('Top 20 Words in Bag-of-Words Representation')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating the tf-idf matrix from the bag of words matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.77 GiB for an array with shape (160000, 3999) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_240\\2584067916.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"user\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbow_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             return_tuple = (\n",
      "\u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m         \u001b[1;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[1;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m         \u001b[0mvectors\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1708\u001b[0m             \u001b[0mTf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1709\u001b[0m         \"\"\"\n\u001b[1;32m-> 1710\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m   1711\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m         )\n\u001b[0;32m   1713\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    601\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    918\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m                 ) from complex_warning\n\u001b[0;32m    920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2082\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m         if (\n\u001b[0;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2087\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.77 GiB for an array with shape (160000, 3999) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if \"user\" in bow_df.columns:\n",
    "    bow_df.drop(columns=['user'], inplace=True)\n",
    "\n",
    "# Extract the BoW matrix and 'Sentiment' column from bow_df\n",
    "X_bow = bow_df.drop(columns=['Sentiment'])\n",
    "y_bow = bow_df['Sentiment']\n",
    "\n",
    "# Initialize the TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y_bow, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Fit and transform the BoW matrix to obtain the TF-IDF matrix\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test)\n",
    "\n",
    "X_pred= tfidf_transformer.transform(test_df['Tweets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### directly creating the tf-idf matrix from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine your positive and negative dataframes\n",
    "X=combined_df['Tweets']\n",
    "y=combined_df['Sentiment']\n",
    "\n",
    "# Assuming 'Tweets' contains the tweet text and 'Sentiment' contains the sentiment labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))  # You can adjust max_features as needed\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "X_pred= tfidf_vectorizer.transform(test_df['Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 50626560000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Extract BERT embeddings for training data\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 30\u001b[0m     train_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Use the embeddings as features for logistic regression\u001b[39;00m\n\u001b[0;32m     33\u001b[0m X_train_features \u001b[38;5;241m=\u001b[39m train_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1014\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1014\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1022\u001b[0m     embedding_output,\n\u001b[0;32m   1023\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1031\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1032\u001b[0m )\n\u001b[0;32m   1033\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:231\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    228\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 231\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m    234\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\torch\\nn\\functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 50626560000 bytes."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Assuming combined_df and test_df are already loaded\n",
    "\n",
    "# Tokenize the tweets using BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_tweets(tweets):\n",
    "    return tokenizer(tweets, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Tokenize the training data\n",
    "tokenized_data = tokenize_tweets(combined_df['Tweets'].explode().tolist())\n",
    "\n",
    "# Add Sentiment labels to tokenized_data\n",
    "tokenized_data['labels'] = combined_df['Sentiment'].tolist()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tokenized_data.input_ids, tokenized_data.labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Extract BERT embeddings for training data\n",
    "with torch.no_grad():\n",
    "    train_outputs = model(input_ids=X_train)\n",
    "\n",
    "# Use the embeddings as features for logistic regression\n",
    "X_train_features = train_outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Train logistic regression model\n",
    "regression_model = LogisticRegression()\n",
    "regression_model.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(input_ids=X_test)\n",
    "\n",
    "X_test_features = test_outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "y_test_pred = regression_model.predict(X_test_features)\n",
    "\n",
    "# Print accuracy on test data\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy on test data: {accuracy}\")\n",
    "\n",
    "# Now, let's use the model to predict on the test_df\n",
    "tokenized_test_data = tokenize_tweets(test_df['Tweets'].explode().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(input_ids=tokenized_test_data.input_ids)\n",
    "\n",
    "X_pred_features = test_outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "y_pred = regression_model.predict(X_pred_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.78      0.80     19993\n",
      "           1       0.79      0.83      0.81     20007\n",
      "\n",
      "    accuracy                           0.81     40000\n",
      "   macro avg       0.81      0.81      0.81     40000\n",
      "weighted avg       0.81      0.81      0.81     40000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the TF-IDF transformed training data\n",
    "logreg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict sentiment on the testing data\n",
    "y_pred = logreg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display additional metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy : 0.801"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Logistic Regression Accuracy: 0.81\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.78      0.80     19993\n",
      "           1       0.79      0.83      0.81     20007\n",
      "\n",
      "    accuracy                           0.81     40000\n",
      "   macro avg       0.81      0.81      0.81     40000\n",
      "weighted avg       0.81      0.81      0.81     40000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the regularized Logistic Regression model (L2 regularization by default)\n",
    "regularized_logreg_model = LogisticRegression(C=1.0, penalty='l2', random_state=42)\n",
    "\n",
    "# Train the model on the TF-IDF transformed training data\n",
    "regularized_logreg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict sentiment on the testing data\n",
    "y_pred_regularized_logreg = regularized_logreg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the regularized model\n",
    "accuracy_regularized_logreg = accuracy_score(y_test, y_pred_regularized_logreg)\n",
    "print(f\"Regularized Logistic Regression Accuracy: {accuracy_regularized_logreg:.2f}\")\n",
    "\n",
    "# Display additional metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_regularized_logreg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mehdi\\anaconda3\\envs\\ada\\lib\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.79\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77     19993\n",
      "           1       0.75      0.88      0.81     20007\n",
      "\n",
      "    accuracy                           0.79     40000\n",
      "   macro avg       0.80      0.79      0.79     40000\n",
      "weighted avg       0.80      0.79      0.79     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Convert -1 to 0 in sentiment labels\n",
    "y_train_binary = y_train.map({-1: 0, 1: 1})\n",
    "y_test_binary = y_test.map({-1: 0, 1: 1})\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the TF-IDF transformed training data\n",
    "xgb_model.fit(X_train_tfidf, y_train_binary)\n",
    "\n",
    "# Predict sentiment on the testing data\n",
    "y_pred_xgb = xgb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_xgb = accuracy_score(y_test_binary, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.2f}\")\n",
    "\n",
    "# Display additional metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_xgb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model on the TF-IDF transformed training data\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict sentiment on the testing data\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.2f}\")\n",
    "\n",
    "# Display additional metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.78\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.78      0.78     19993\n",
      "           1       0.78      0.78      0.78     20007\n",
      "\n",
      "    accuracy                           0.78     40000\n",
      "   macro avg       0.78      0.78      0.78     40000\n",
      "weighted avg       0.78      0.78      0.78     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model on the TF-IDF transformed training data\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict sentiment on the testing data\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.2f}\")\n",
    "\n",
    "# Display additional metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy : 0.760"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    This function creates a csv file named 'name' in the format required for a submission in Kaggle or AIcrowd.\n",
    "    The file will contain two columns the first with 'ids' and the second with 'y_pred'.\n",
    "    y_pred must be a list or np.array of 1 and -1 otherwise the function will raise a ValueError.\n",
    "\n",
    "    Args:\n",
    "        ids (list,np.array): indices\n",
    "        y_pred (list,np.array): predictions on data correspondent to indices\n",
    "        name (str): name of the file to be created\n",
    "    \"\"\"\n",
    "    # Check that y_pred only contains -1 and 1\n",
    "    if not all(i in [-1, 1] for i in y_pred):\n",
    "        raise ValueError(\"y_pred can only contain values -1, 1\")\n",
    "\n",
    "    with open(name, \"w\", newline=\"\") as csvfile:\n",
    "        fieldnames = [\"Id\", \"Prediction\"]\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({\"Id\": int(r1), \"Prediction\": int(r2)})\n",
    "\n",
    "#!!!!don't forget to change the name of the model!!!!\n",
    "ids=np.arange(1,len(y_pred)+1)\n",
    "y_subm=logreg_model.predict(X_pred)\n",
    "create_csv_submission(ids, y_subm, \"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
